{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('synthetic_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of days from Invoice Date to Payment Date\n",
    "def calculate_days_from_invoice_to_payment(data):\n",
    "    # Convert 'Invoice Date' and 'Payment Date' to datetime\n",
    "    data['Invoice Date'] = pd.to_datetime(data['Invoice Date'], errors='coerce')\n",
    "    data['Payment Date'] = pd.to_datetime(data['Payment Date'], errors='coerce')\n",
    "    \n",
    "    # Calculate the difference between 'Payment Date' and 'Invoice Date' in days\n",
    "    data['Days_from_Invoice_to_Payment'] = (data['Payment Date'] - data['Invoice Date']).dt.days\n",
    "    \n",
    "    # Handle missing values by filling with a placeholder, or you could drop them\n",
    "    data['Days_from_Invoice_to_Payment'].fillna(-1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply One-Class SVM for anomaly detection on a specific feature\n",
    "def detect_anomalies_with_ocsvm(data, feature_name, nu=0.1, gamma='scale'):\n",
    "    # Extract the feature and reshape for One-Class SVM\n",
    "    feature = data[feature_name].values.reshape(-1, 1)\n",
    "    \n",
    "    # Scale the feature\n",
    "    scaler = StandardScaler()\n",
    "    feature_scaled = scaler.fit_transform(feature)\n",
    "    \n",
    "    # Train the One-Class SVM\n",
    "    ocsvm = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "    ocsvm.fit(feature_scaled)\n",
    "    \n",
    "    # Predict anomalies (-1 indicates anomaly, 1 indicates normal)\n",
    "    predictions = ocsvm.predict(feature_scaled)\n",
    "    \n",
    "    # Add the anomaly column to the dataframe\n",
    "    data[f'{feature_name} Anomaly'] = np.where(predictions == -1, 'Anomaly', 'Normal')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect irregular currency patterns (supplier-specific anomalies)\n",
    "def detect_irregular_currency_pattern(data):\n",
    "    # Ensure column names are correctly named and clean\n",
    "    data.columns = data.columns.str.strip()  # Strip any extra spaces in column names\n",
    "    \n",
    "    # Step 1: Check if 'Supplier Name' and 'Currency Code' are available\n",
    "    if 'Supplier Name' not in data.columns or 'Currency Code' not in data.columns:\n",
    "        raise ValueError(\"The dataset must contain 'Supplier Name' and 'Currency Code' columns\")\n",
    "    \n",
    "    # Step 2: Handle missing values in 'Currency Code' or 'Supplier Name'\n",
    "    data['Currency Code'].fillna('Unknown', inplace=True)\n",
    "    data['Supplier Name'].fillna('Unknown Supplier', inplace=True)\n",
    "    \n",
    "    # Step 3: Find the most common currency used by each supplier\n",
    "    most_common_currency = data.groupby('Supplier Name')['Currency Code'].agg(lambda x: x.mode()[0] if not x.mode().empty else 'Unknown')\n",
    "\n",
    "    # Step 4: Create a new column for currency anomalies\n",
    "    data['Currency Anomaly'] = None\n",
    "    \n",
    "    # Step 5: Loop through each supplier and check for anomalies\n",
    "    for supplier in data['Supplier Name'].unique():\n",
    "        common_currency = most_common_currency[supplier]\n",
    "        supplier_data = data[data['Supplier Name'] == supplier]\n",
    "        \n",
    "        # Step 6: Flag any invoice that doesn't match the most common currency\n",
    "        anomaly_rows = supplier_data[supplier_data['Currency Code'] != common_currency]\n",
    "        if not anomaly_rows.empty:\n",
    "            data.loc[anomaly_rows.index, 'Currency Anomaly'] = f\"Irregular currency: {common_currency} vs {anomaly_rows['Currency Code'].values[0]}\"\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect typos in 'Supplier Name' using fuzzy matching\n",
    "def detect_supplier_name_typos(data, threshold=60):\n",
    "    # Initialize the anomaly column\n",
    "    data['Supplier Name Anomaly'] = 'Normal'\n",
    "    \n",
    "    # Step 1: Calculate the most common name for each supplier\n",
    "    for supplier in data['Supplier Name'].unique():\n",
    "        # Find the most common variant of the supplier name in the dataset\n",
    "        supplier_data = data[data['Supplier Name'] == supplier]\n",
    "        \n",
    "        # Use the first occurrence as the most common name\n",
    "        common_name = supplier_data.iloc[0]['Supplier Name']\n",
    "        \n",
    "        # Step 2: Loop through the rows and calculate similarity score\n",
    "        for index, row in supplier_data.iterrows():\n",
    "            # Compare the supplier name to the most common name using fuzzy matching\n",
    "            similarity_score = fuzz.ratio(row['Supplier Name'], common_name)\n",
    "            \n",
    "            # Step 3: If the similarity score is below the threshold, mark it as an anomaly\n",
    "            if similarity_score < threshold:\n",
    "                data.at[index, 'Supplier Name Anomaly'] = f\"Typo detected (Similarity: {similarity_score})\"\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def detect_supplier_name_anomalies(data, min_samples=2, eps=0.5):\n",
    "    # Step 1: Vectorize the supplier names using TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(data['Supplier Name'])\n",
    "\n",
    "    # Step 2: Apply DBSCAN clustering\n",
    "    db = DBSCAN(min_samples=min_samples, eps=eps, metric='cosine')\n",
    "    clusters = db.fit_predict(tfidf_matrix)\n",
    "\n",
    "    # Step 3: Add cluster labels to the data\n",
    "    data['Cluster'] = clusters\n",
    "\n",
    "    # Step 4: Flag outliers (cluster label == -1) as anomalies\n",
    "    data['Supplier Name Anomaly'] = data['Cluster'].apply(lambda x: 'Anomaly' if x == -1 else 'Normal')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect irregular 'Gross Amount' using Z-scores\n",
    "def detect_gross_amount_anomalies(data):\n",
    "    data['Gross Amount Anomaly'] = None\n",
    "    z_scores = stats.zscore(data['Gross Amount'])\n",
    "    threshold = 3\n",
    "    data['Gross Amount Anomaly'] = np.where(np.abs(z_scores) > threshold, \"Anomaly\", \"Normal\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine all anomalies detected for a final anomaly message\n",
    "def combine_anomalies(data):\n",
    "    anomaly_columns = ['Currency Anomaly', 'Supplier Name Anomaly', 'Gross Amount Anomaly']\n",
    "    data['Final Anomaly'] = data[anomaly_columns].apply(lambda x: ', '.join(x.dropna()), axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhireen Kumar Rajak\\AppData\\Local\\Temp\\ipykernel_29900\\420011190.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Days_from_Invoice_to_Payment'].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = detect_supplier_name_anomalies(data, min_samples=2, eps=0.5)\n",
    "# Apply One-Class SVM to detect anomalies in specific numeric features\n",
    "data = detect_anomalies_with_ocsvm(data, 'Gross Amount')\n",
    "data = detect_anomalies_with_ocsvm(data, 'VAT Amount')\n",
    "\n",
    "# Apply the calculation function to get 'Days_from_Invoice_to_Payment'\n",
    "data = calculate_days_from_invoice_to_payment(data)\n",
    "data = detect_anomalies_with_ocsvm(data, 'Days_from_Invoice_to_Payment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhireen Kumar Rajak\\AppData\\Local\\Temp\\ipykernel_29900\\3058818282.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Currency Code'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Dhireen Kumar Rajak\\AppData\\Local\\Temp\\ipykernel_29900\\3058818282.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Supplier Name'].fillna('Unknown Supplier', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Apply custom anomaly detection functions for categorical and other types of anomalies\n",
    "data = detect_irregular_currency_pattern(data)\n",
    "# data = detect_supplier_name_typos(data)\n",
    "data = detect_gross_amount_anomalies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all anomaly columns into one\n",
    "data = combine_anomalies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Supplier Name  Gross Amount Currency Code   Final Anomaly\n",
      "0  Global Tech Solutions       1606.12           EUR  Normal, Normal\n",
      "1        Eco Electronics        139.07           JPY  Normal, Normal\n",
      "2      Velocity Ventures       3096.84           USD  Normal, Normal\n",
      "3        Eco Electronics       2205.86           JPY  Normal, Normal\n",
      "4       Blue Banana Inc.       4093.04           USD  Normal, Normal\n"
     ]
    }
   ],
   "source": [
    "# Show the updated dataset with all anomaly columns\n",
    "print(data[['Supplier Name', 'Gross Amount', 'Currency Code', 'Final Anomaly']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processed data with anomalies has been exported to 'processed_data_with_anomalies.csv'\n"
     ]
    }
   ],
   "source": [
    "# After processing all anomaly detection functions, export the result to CSV\n",
    "data.to_csv('processed_data_with_anomalies.csv', index=False)\n",
    "\n",
    "print(\"The processed data with anomalies has been exported to 'processed_data_with_anomalies.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
